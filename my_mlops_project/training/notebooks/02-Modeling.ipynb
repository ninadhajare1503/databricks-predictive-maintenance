{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c173da1-047d-46b9-b4a3-8653e6f1cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved data pipeline is ready for modeling.\n",
      "Number of features: 21\n",
      "X_train_scaled shape: (16504, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "df = pd.read_csv('../data/train_FD001.csv')\n",
    "\n",
    "# --- 2. Feature Selection (from EDA) ---\n",
    "# Drop the constant columns we identified in our EDA\n",
    "columns_to_drop = [\n",
    "    'sensor_measurement_1', 'sensor_measurement_5', 'sensor_measurement_6',\n",
    "    'sensor_measurement_10', 'sensor_measurement_16', 'sensor_measurement_18',\n",
    "    'sensor_measurement_19'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# --- 3. Feature Engineering (from EDA) ---\n",
    "# Create rolling average features for the most promising sensors\n",
    "window_size = 10\n",
    "promising_sensors = [\n",
    "    'sensor_measurement_4', 'sensor_measurement_7', 'sensor_measurement_11', 'sensor_measurement_12'\n",
    "]\n",
    "for sensor in promising_sensors:\n",
    "    df[f'{sensor}_rolling_avg'] = df.groupby('unit_number')[sensor].transform(\n",
    "        lambda x: x.rolling(window_size, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# --- 4. Create the Target Variable ---\n",
    "max_cycles = df.groupby('unit_number')['time_in_cycles'].max()\n",
    "df = df.merge(max_cycles.to_frame(name='max_cycles'), left_on='unit_number', right_index=True)\n",
    "df['RUL'] = df['max_cycles'] - df['time_in_cycles']\n",
    "df['label'] = (df['RUL'] <= 30).astype(int)\n",
    "\n",
    "# --- 5. Final Feature Selection and Splitting ---\n",
    "# IMPORTANT: Our feature list now includes the new rolling average features!\n",
    "feature_cols = [col for col in df.columns if 'op_setting' in col or 'sensor' in col]\n",
    "\n",
    "# Define X and y\n",
    "X = df[feature_cols]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 6. Scale the Data ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Improved data pipeline is ready for modeling.\")\n",
    "print(f\"Number of features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1f1482-5a5a-45d1-9769-85af4dc582f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/19 23:57:07 INFO mlflow.tracking.fluent: Experiment with name 'Predictive Maintenance - Feature Engineered' does not exist. Creating a new experiment.\n",
      "2025/09/19 23:57:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/19 23:57:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (Feature Engineered) run logged with accuracy: 0.9661\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NinXD\\ML-Ops\\mlops-predictive-maintenance\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.1887 - val_accuracy: 0.9509 - val_loss: 0.1125\n",
      "Epoch 2/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1208 - val_accuracy: 0.9576 - val_loss: 0.1028\n",
      "Epoch 3/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1110 - val_accuracy: 0.9606 - val_loss: 0.0977\n",
      "Epoch 4/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1062 - val_accuracy: 0.9579 - val_loss: 0.0978\n",
      "Epoch 5/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1018 - val_accuracy: 0.9627 - val_loss: 0.0915\n",
      "Epoch 6/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1000 - val_accuracy: 0.9597 - val_loss: 0.0923\n",
      "Epoch 7/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.0974 - val_accuracy: 0.9624 - val_loss: 0.0883\n",
      "Epoch 8/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9586 - loss: 0.0975 - val_accuracy: 0.9627 - val_loss: 0.0914\n",
      "Epoch 9/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.0965 - val_accuracy: 0.9643 - val_loss: 0.0889\n",
      "Epoch 10/10\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.0955 - val_accuracy: 0.9640 - val_loss: 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/19 23:57:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/19 23:57:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/09/19 23:57:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (Feature Engineered) run logged with accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set a new experiment name to keep results separate\n",
    "mlflow.set_experiment(\"Predictive Maintenance - Feature Engineered\")\n",
    "\n",
    "# --- Run 1: Random Forest on Engineered Features ---\n",
    "with mlflow.start_run(run_name=\"Random Forest (Feature Engineered)\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"features_used\", X_train_scaled.shape[1])\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate and log metrics\n",
    "    y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_rf)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(rf_model, \"random_forest_model_v2\")\n",
    "    \n",
    "    print(f\"\\nRandom Forest (Feature Engineered) run logged with accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# --- Run 2: Neural Network on Engineered Features ---\n",
    "with mlflow.start_run(run_name=\"Neural Network (Feature Engineered)\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", 10)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"features_used\", X_train_scaled.shape[1])\n",
    "    mlflow.log_param(\"model_type\", \"TensorFlow/Keras\")\n",
    "    \n",
    "    # Define and compile the model (using the same architecture as before)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate and log metrics\n",
    "    loss, accuracy_nn = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_nn)\n",
    "    mlflow.log_metric(\"loss\", loss)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.tensorflow.log_model(model, \"neural_network_model_v2\")\n",
    "\n",
    "    print(f\"Neural Network (Feature Engineered) run logged with accuracy: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57cf6f-1320-4f67-8ec0-94489d1aa387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
